{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "08b491ad-c599-4b42-980c-d11e9598e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a Trigram based Neural Network\n",
    "In this section, we are performing the following tasks:\n",
    "    1.  Importing the dataset(data)\n",
    "    2.  Shuffling the dataset\n",
    "    3.  Dividing it into train-dev-test(80-10-10) split \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "words = open('names.txt', 'r').read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2bfee548-6c8c-40c2-a5a1-62534f30939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a string to index and index to string mapping\n",
    "\"\"\"\n",
    "def build_character_mappings(words):\n",
    "    chars = sorted(list(set(''.join(words)))) # Contains the list of all the alphabets in asending order\n",
    "    stoi = {s: i+1 for i,s in enumerate(chars)} # contains the string to index mapping\n",
    "    stoi['.'] = 0 # Signifies the start/end of a word\n",
    "    itos = {i:s for s,i in stoi.items()} # contans the index to string mapping\n",
    "    return {'stoi': stoi, 'itos': itos}\n",
    "\n",
    "character_mappings = build_character_mappings(words)\n",
    "stoi = character_mappings['stoi']\n",
    "itos = character_mappings['itos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c54c8a82-c887-4d9a-b417-47a815cdc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "def convert_words_to_index(data, stoi):\n",
    "    xs, ys = [], []\n",
    "    for w in data:    \n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            ix1 = stoi[ch1]\n",
    "            ix2 = stoi[ch2]\n",
    "            ix3 = stoi[ch3]\n",
    "            xs.append(ix1 * 27 + ix2)\n",
    "            ys.append(ix3)\n",
    "\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    # num = xs.nelement()\n",
    "    return {'xs': xs, 'ys': ys}\n",
    "\n",
    "dataset = convert_words_to_index(words, stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79dc890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_dev_split(dataset):\n",
    "    # Defining the split ratio train-dev-test 80: 10: 10\n",
    "    n_size = dataset['xs'].size(0)\n",
    "    n_train = int(0.8 * n_size)\n",
    "    n_dev = int(0.1 * n_size)\n",
    "    n_test = n_size - n_train - n_dev\n",
    "\n",
    "    # Shuffle the data\n",
    "    perm = torch.randperm(n_size)\n",
    "    xs_shuffled = dataset['xs'][perm]\n",
    "    ys_shuffled = dataset['ys'][perm]\n",
    "\n",
    "    # Split the input data\n",
    "    train_x = xs_shuffled[:n_train]\n",
    "    dev_x = xs_shuffled[n_train:n_train + n_dev]\n",
    "    test_x = xs_shuffled[n_train + n_dev:]\n",
    "\n",
    "    # Split the labels\n",
    "    train_y = ys_shuffled[:n_train]\n",
    "    dev_y = ys_shuffled[n_train:n_train + n_dev]\n",
    "    test_y = ys_shuffled[n_train + n_dev:]\n",
    "\n",
    "    return {'train_x': train_x, 'train_y': train_y,\n",
    "            'dev_x': dev_x, 'dev_y': dev_y,\n",
    "            'test_x': test_x, 'test_y': test_y}\n",
    "\n",
    "splitted_dataset = train_test_dev_split(dataset)\n",
    "train_x = splitted_dataset['train_x']\n",
    "train_y = splitted_dataset['train_y']\n",
    "dev_x = splitted_dataset['dev_x']\n",
    "dev_y = splitted_dataset['dev_y']\n",
    "test_x = splitted_dataset['test_x']\n",
    "test_y = splitted_dataset['test_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7d0ef3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    1.  Initialize the Network: Randomly initialize 27 neurons' weights. \n",
    "    2.  Each neuron receives 27 inputs.\n",
    "\"\"\"\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27 * 27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05a3bd51-a7b9-48b9-af56-7a2b1853c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this sectiion, we are:\n",
    "    1.  We are running the forward pass\n",
    "    2.  Backward pass\n",
    "    3.  Updating the weights\n",
    "\"\"\"\n",
    "NUM_EPOCHS = 50\n",
    "WGT_UPDATE_COFF = 10\n",
    "losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Forward Pass\n",
    "    xenc = F.one_hot(train_x, num_classes=729).float() # Input to the network: one-hot encoding. O/P: Tensor(train_x, 729)\n",
    "    logits = xenc @ W # predict log-counts: (228146, 27) @ (27, 27) => (228146, 27)\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    num = train_x.size(0)\n",
    "    probs = counts / counts.sum(1, keepdims=True) # Probablities for next character\n",
    "    loss = -probs[torch.arange(num), train_y].log().mean() + 0.01*(W**2).mean()\n",
    "    losses.append(loss.item())\n",
    "    # Backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    W.data += -WGT_UPDATE_COFF * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3628c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss graph\n",
    "def plot_losses():\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), losses, marker='o')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss vs. Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "13b359c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.backends.cuda' has no attribute 'is_available'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.backends.cuda' has no attribute 'is_available'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3e347e4-65b5-481d-b277-b8a7ad471ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "ishaleufrlpozwelananesh.\n",
      "ogudeladqlegchalaroglotilvanipakemapalejanisu.\n",
      "ozhpzankhatodezayranarivqfvmixqaushauydmesapxxradarmelezusozanonxw.\n",
      "maalanoivypaburiaeluusahaluyjariparhakelhgdalarchaveipamarmanihalbrtaisahaaniyykitvaaw.\n"
     ]
    }
   ],
   "source": [
    "# Performing a prediction using Trigram model\n",
    "for i in range(5):\n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=729).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
